{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import shape, matrix, log, exp, zeros,random,dot,multiply\n",
    "from mnist import readWithoutBias\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_train, label_train = readWithoutBias(dataset=\"training\")\n",
    "data_test, label_test = readWithoutBias(dataset=\"testing\")\n",
    "label_train = matrix(label_train)\n",
    "label_test  = matrix(label_test)\n",
    "data_train  = matrix(data_train).T\n",
    "data_test   = matrix(data_test).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apoorve/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:3: RuntimeWarning: invalid value encountered in divide\n",
      "  app.launch_new_instance()\n",
      "/Users/apoorve/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:4: RuntimeWarning: divide by zero encountered in divide\n",
      "/Users/apoorve/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:4: RuntimeWarning: invalid value encountered in divide\n"
     ]
    }
   ],
   "source": [
    "train_mean  = data_train.mean(axis=1)\n",
    "train_std   = data_train.std(axis=1)\n",
    "data_train  = np.nan_to_num((data_train - train_mean)/train_std)\n",
    "data_test   = np.nan_to_num((data_test - train_mean)/train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test = data_test\n",
    "y_test = label_test\n",
    "\n",
    "train = zip(data_train.T,label_train)\n",
    "mini_batch_size = 10\n",
    "\n",
    "n_input = shape(data_train)[0] # excluding bias term\n",
    "n_hidden = 30               # excluding bias term\n",
    "n_output = 10\n",
    "epochs = 10\n",
    "alpha = 0.1\n",
    "mini_batch_size = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "theta1 = matrix(random.randn(n_hidden,n_input))/sqrt(n_input)\n",
    "bias1  = matrix(random.randn(n_hidden,1))\n",
    "theta2 = matrix(random.randn(n_output,n_hidden))/sqrt(n_hidden)\n",
    "bias2  = matrix(random.randn(n_output,1))\n",
    "\n",
    "afunc, afuncGradient = act_funcs[\"sigmoid\"]\n",
    "\n",
    "#Regularization term\n",
    "lam = 0.0\n",
    "\n",
    "#Momentum Term\n",
    "gamma = 0.0\n",
    "v1 = np.zeros_like(theta1)\n",
    "vb1= np.zeros_like(bias1)\n",
    "v2 = np.zeros_like(theta2)\n",
    "vb2= np.zeros_like(bias2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layers:\t\t\t3\n",
      "Hidden Nodes:\t\t30\n",
      "Epochs:\t\t\t10\n",
      "LearningRate:\t\t0.1\n",
      "Mini Batch Size:\t10\n",
      "Activation Fn:\t\ttanh\n",
      "Gamma(Momentum):\t0.0\n",
      "Lambda(Regularize):\t0.0\n",
      "Epoch 1 train,test accuracy:\t0.929516666667 0.9219\n",
      "Epoch 2 train,test accuracy:\t0.9389 0.9274\n",
      "Epoch 3 train,test accuracy:\t0.944583333333 0.9344\n",
      "Epoch 4 train,test accuracy:\t0.946416666667 0.9338\n",
      "Epoch 5 train,test accuracy:\t0.951266666667 0.9341\n",
      "Epoch 6 train,test accuracy:\t0.953616666667 0.9374\n",
      "Epoch 7 train,test accuracy:\t0.954083333333 0.9348\n",
      "Epoch 8 train,test accuracy:\t0.956233333333 0.9364\n",
      "Epoch 9 train,test accuracy:\t0.958216666667 0.9373\n",
      "Epoch 10 train,test accuracy:\t0.958 0.9368\n"
     ]
    }
   ],
   "source": [
    "print \"Layers:\\t\\t\\t\", 3\n",
    "print \"Hidden Nodes:\\t\\t\",n_hidden\n",
    "print \"Epochs:\\t\\t\\t\", epochs\n",
    "print \"LearningRate:\\t\\t\",alpha\n",
    "print \"Mini Batch Size:\\t\",mini_batch_size\n",
    "print \"Activation Fn:\\t\\ttanh\"\n",
    "print \"Gamma(Momentum):\\t\",gamma\n",
    "print \"Lambda(Regularize):\\t\",lam\n",
    "\n",
    "for i in range(epochs):\n",
    "    random.shuffle(train)\n",
    "    mini_batches = [train[k:k+mini_batch_size] for k in xrange(0,len(train),mini_batch_size)]\n",
    "    for mini_batch in mini_batches:\n",
    "        d1  = np.zeros_like(theta1)\n",
    "        d2  = np.zeros_like(theta2)\n",
    "        db1 = np.zeros_like(bias1)\n",
    "        db2 = np.zeros_like(bias2)\n",
    "        \n",
    "        for X,y in mini_batch:\n",
    "            gradTheta1, gradBias1, gradTheta2, gradBias2 = \\\n",
    "                backPropGradient(X.T, y, theta1, theta2, bias1, bias2) #just one example passed\n",
    "            d1  += gradTheta1\n",
    "            db1 += gradBias1\n",
    "            d2  += gradTheta2\n",
    "            db2 += gradBias2\n",
    "            \n",
    "        d1   = d1/mini_batch_size + lam*theta1\n",
    "        db1  = db1/mini_batch_size\n",
    "        d2   = d2/mini_batch_size + lam*theta2\n",
    "        db2  = db2/mini_batch_size\n",
    "        \n",
    "        v1 = alpha*d1  + v1*gamma\n",
    "        vb1= alpha*db1 + vb1*gamma\n",
    "        v2 = alpha*d2  + v2*gamma\n",
    "        vb2= alpha*db2 + vb2*gamma\n",
    "        \n",
    "        theta1 = theta1 - v1\n",
    "        bias1  = bias1  - vb1\n",
    "        theta2 = theta2 - v2\n",
    "        bias2  = bias2  - vb2\n",
    "    print \"Epoch\",i+1,\"train,test accuracy:\\t\",accuracy(data_train, label_train, theta1, theta2, bias1, bias2), \\\n",
    "            accuracy(data_test, label_test , theta1, theta2, bias1, bias2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking backpropgradient vs numerical gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.62795166236e-10\n",
      "-1.45355906397e-09\n",
      "-1.01694661481e-10\n",
      "-8.43307289101e-09\n"
     ]
    }
   ],
   "source": [
    "X, y = train[0]\n",
    "X = X.T\n",
    "gradTheta1, gradBias1, gradTheta2, gradBias2 = backPropGradient(X,y,theta1,theta2, bias1, bias2)\n",
    "numGrad1,numGradBias1,numGrad2,numGradBias2  = numericalGradient(X,y,theta1,theta2, bias1, bias2)\n",
    "print np.sum(np.subtract(numGradBias2,gradBias2))\n",
    "print np.sum(np.subtract(numGradBias1,gradBias1))\n",
    "print np.sum(np.subtract(numGrad2,gradTheta2))\n",
    "print np.sum(np.subtract(numGrad1,gradTheta1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.62795166236e-11\n",
      "-4.84519687989e-11\n",
      "-3.38982204936e-13\n",
      "-3.58549017475e-13\n"
     ]
    }
   ],
   "source": [
    "print np.mean(np.subtract(numGradBias2,gradBias2))\n",
    "print np.mean(np.subtract(numGradBias1,gradBias1))\n",
    "print np.mean(np.subtract(numGrad2,gradTheta2))\n",
    "print np.mean(np.subtract(numGrad1,gradTheta1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.21693252434e-11\n",
      "1.36737973808e-10\n",
      "1.76029912868e-10\n",
      "1.79982517778e-09\n",
      "-6.05020478162e-11\n",
      "-2.40977672712e-10\n",
      "-1.39576128433e-10\n",
      "-1.98751259894e-09\n"
     ]
    }
   ],
   "source": [
    "print np.max(np.subtract(numGradBias2,gradBias2))\n",
    "print np.max(np.subtract(numGradBias1,gradBias1))\n",
    "print np.max(np.subtract(numGrad2,gradTheta2))\n",
    "print np.max(np.subtract(numGrad1,gradTheta1))\n",
    "\n",
    "print np.min(np.subtract(numGradBias2,gradBias2))\n",
    "print np.min(np.subtract(numGradBias1,gradBias1))\n",
    "print np.min(np.subtract(numGrad2,gradTheta2))\n",
    "print np.min(np.subtract(numGrad1,gradTheta1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def accuracy(X, y, theta1, theta2, bias1, bias2):\n",
    "    a1 = X\n",
    "    z2 = dot(theta1,a1) + bias1\n",
    "    a2 = afunc(z2)\n",
    "    z3 = dot(theta2,a2) + bias2\n",
    "    a3 = sigmoid(z3)\n",
    "    \n",
    "    pred = np.argmax(a3,axis=0)\n",
    "    return np.sum(np.equal(pred,y.T))/float(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def backPropGradient(X, y, theta1, theta2, bias1, bias2):\n",
    "    a1 = X\n",
    "    z2 = dot(theta1,a1) + bias1\n",
    "    a2 = afunc(z2)\n",
    "    z3 = dot(theta2,a2) + bias2\n",
    "    a3 = sigmoid(z3)\n",
    "    \n",
    "    t = np.zeros_like(a3)\n",
    "    for i in range(len(y)):\n",
    "        t[y[i],i] = 1\n",
    "    \n",
    "    delta3 = a3-t #shape (10,1)\n",
    "    delta2 = dot(theta2.T,delta3)#shape (100,10)X(10,1) = (100,1)\n",
    "    delta2 = multiply(delta2,afuncGradient(z2))\n",
    "\n",
    "    gradTheta2 = dot(delta3,a2.T)\n",
    "    gradBias2  = delta3\n",
    "    gradTheta1 = dot(delta2,a1.T)\n",
    "    gradBias1  = delta2\n",
    "    return gradTheta1, gradBias1, gradTheta2, gradBias2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def errorFn(X, y, theta1, theta2, bias1, bias2):\n",
    "    n_examples = shape(X)[1]\n",
    "    a1 = X\n",
    "    z2 = dot(theta1,a1) + bias1\n",
    "    a2 = afunc(z2)\n",
    "    z3 = dot(theta2,a2) + bias2\n",
    "    a3 = sigmoid(z3)\n",
    "    \n",
    "    t = np.zeros_like(a3)\n",
    "    for i in range(len(y)):\n",
    "        t[y[i],i] = 1\n",
    "\n",
    "    error = np.sum(multiply(t,log(a3)) + multiply((1-t),log(1-a3)))\n",
    "    error = -error/n_examples\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def numericalGradient(X, y, theta1, theta2, bias1, bias2):\n",
    "    epsilon = 10**-5\n",
    "    numGrad1     = np.zeros_like(theta1)\n",
    "    numGradBias1 = np.zeros_like(bias1)\n",
    "    numGrad2     = np.zeros_like(theta2)\n",
    "    numGradBias2 = np.zeros_like(bias2)\n",
    "    \n",
    "    for i in range(shape(theta1)[0]):\n",
    "        for j in range(shape(theta1)[1]):\n",
    "            theta1_pos = np.copy(theta1)\n",
    "            theta1_neg = np.copy(theta1)\n",
    "            theta1_pos[i,j] += epsilon\n",
    "            theta1_neg[i,j] -= epsilon\n",
    "            numGrad1[i,j]    = (errorFn(X, y, theta1_pos, theta2, bias1, bias2) - \\\n",
    "                                errorFn(X, y, theta1_neg, theta2, bias1, bias2))/2/epsilon\n",
    "    for i in range(shape(theta2)[0]):\n",
    "        for j in range(shape(theta2)[1]):\n",
    "            theta2_pos = np.copy(theta2)\n",
    "            theta2_neg = np.copy(theta2)\n",
    "            theta2_pos[i,j] += epsilon\n",
    "            theta2_neg[i,j] -= epsilon\n",
    "            numGrad2[i,j]    = (errorFn(X, y, theta1, theta2_pos, bias1, bias2) - \\\n",
    "                                errorFn(X, y, theta1, theta2_neg, bias1, bias2))/2/epsilon\n",
    "    for i in range(shape(bias1)[0]):\n",
    "        for j in range(shape(bias1)[1]):\n",
    "            bias1_pos         = np.copy(bias1)\n",
    "            bias1_neg         = np.copy(bias1)\n",
    "            bias1_pos[i,j]   += epsilon\n",
    "            bias1_neg[i,j]   -= epsilon\n",
    "            numGradBias1[i,j] = (errorFn(X, y, theta1, theta2, bias1_pos, bias2) - \\\n",
    "                                errorFn(X, y, theta1, theta2, bias1_neg, bias2))/2/epsilon\n",
    "    for i in range(shape(bias2)[0]):\n",
    "        for j in range(shape(bias2)[1]):\n",
    "            bias2_pos         = np.copy(bias2)\n",
    "            bias2_neg         = np.copy(bias2)\n",
    "            bias2_pos[i,j]   += epsilon\n",
    "            bias2_neg[i,j]   -= epsilon\n",
    "            numGradBias2[i,j] = (errorFn(X, y, theta1, theta2, bias1, bias2_pos) - \\\n",
    "                                errorFn(X, y, theta1, theta2, bias1, bias2_neg))/2/epsilon\n",
    "    return numGrad1,numGradBias1,numGrad2,numGradBias2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sigmoid = lambda z: 1.0/(1.0+np.exp(-z))\n",
    "sigmoid_prime = lambda z: multiply(sigmoid(z),(1-sigmoid(z)))\n",
    "ftanh = lambda z: np.tanh(z)\n",
    "ftanh_prime = lambda z: 1 - multiply(ftanh(z),ftanh(z))\n",
    "funny_tanh = lambda z: 1.7159 * np.tanh(2.0/3.0 * z) + .001*z\n",
    "funny_tanh_prime = lambda z: 1.7159 * 2.0 / 3.0 * (1.0 / multiply(np.cosh(2.0/3.0 * z),np.cosh(2.0/3.0 * z))) + .001\n",
    "relu = lambda z: multiply(z,(z > 0))\n",
    "relu_prime = lambda z: z >= 0\n",
    "leaky_relu = lambda z: np.maximum(.1*z, z)\n",
    "leaky_relu_prime = lambda z: 1*(z>=0) + .1*(z<0)\n",
    "\n",
    "act_funcs = {'sigmoid': (sigmoid, sigmoid_prime),\n",
    "             'ftanh': (ftanh, ftanh_prime),\n",
    "             'funny_tanh': (funny_tanh, funny_tanh_prime),\n",
    "             'relu': (relu,relu_prime),\n",
    "             'leaky_relu': (leaky_relu,leaky_relu_prime)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
